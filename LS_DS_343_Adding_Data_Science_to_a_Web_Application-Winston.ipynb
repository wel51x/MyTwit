{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Lambda School Data Science_\n",
    "## Productization Module 3, [Adding Data Science to a Web AppIication](https://github.com/LambdaSchool/DS-Unit-3-Sprint-4-Productization-and-Cloud/blob/master/module3-adding-data-science-to-a-web-application/README.md)\n",
    "\n",
    "## Today's Plan:\n",
    "\n",
    "### Templates (provided for you)\n",
    "- `base.html`\n",
    "- `prediction.html`\n",
    "- `user.html`\n",
    "\n",
    "### Functions (added by you)\n",
    "\n",
    "#### `twitter.py`\n",
    "- `add_or_update_user`\n",
    "- `add_users`\n",
    "- `update_all_users`\n",
    "\n",
    "#### `predict.py`\n",
    "- `predict_user`\n",
    "\n",
    "#### `app.py`\n",
    "- ` @app.route('/user/<name>', methods=['GET'])`\n",
    "- ` @app.route('/user', methods=['POST'])`\n",
    "- ` @app.route('/compare', methods=['POST'])`\n",
    "- ` @app.route('/update')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [GET and POST methods, explained](https://developer.mozilla.org/en-US/docs/Web/HTTP/Session#Request_methods)\n",
    "\n",
    "HTTP defines a set of request methods indicating the desired action to be performed upon a resource. The most common requests are `GET` and `POST`:\n",
    "\n",
    "- The `GET` method requests a data representation of the specified resource. Requests using `GET` should only retrieve data.\n",
    "- The `POST` method sends data to a server so it may change its state. This is the method often used for HTML Forms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. route `/user/<name>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prototype interactively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flask.app.Flask"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mytwit.__init__ import *\n",
    "from mytwit.twitter import *\n",
    "\n",
    "type(APP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What % of tax filings could be 100% automated? If the government guessed as to what your return should look like, it‚Äôd probably be 100% right... 90% of the time? https://t.co/CSS9KgQv8v\n",
      "Just hit 24 Lambda School students with job offers so far this month. We're 9 days in.\n",
      "RT @jeremybrady702: All I have to say is @LambdaSchool has taken my breath away with kindness tonight, thank you soo much!\n",
      "There is nothing better than talking to recently hired Lambda School grads https://t.co/zRfvxTMFBI\n",
      "I declare DM bankruptcy again, just FYI. Honestly considering locking it down.\n",
      "RT @tstock915: ‚ÄúIf vocational schools aren‚Äôt willing to put their money where their mouth is and offer ISA‚Äôs, they‚Äôll probably be dead with‚Ä¶\n",
      "Here's what few people get about ISAs:\n",
      "\n",
      "If you don't have good terms, you have negative selection bias, and ISAs won't perform.\n",
      "\n",
      "To avoid selection bias you need to have both great terms &amp; great outcomes.\n",
      "\n",
      "If any of that is off it all fails.\n",
      "RT @Austen: Lambda School is hiring a GM of India.\n",
      "\n",
      "This person will be well compensated ($115k/yr US = 79 lakhs/yr), and will own the enti‚Ä¶\n",
      "RT @IrvingD57747608: Working on the pokedex case tonight, was worried the raspberry pi would be to big as it was, luckily I came prepared w‚Ä¶\n",
      "In the next couple years Lambda School could have an ISA payment cap lower than the upfront cost of code schools today.\n",
      "\n",
      "Better education, better outcomes, no financial risk, no payment if you‚Äôre not hired, and cheaper in literally every scenario.\n",
      "Lambda School is hiring a GM of India.\n",
      "\n",
      "This person will be well compensated ($115k/yr US = 79 lakhs/yr), and will own the entire P&amp;L.\n",
      "\n",
      "Someone technical, Indian roots + experience at high-growth startup(s). Experience at top SV companies/founding ideal.\n",
      "\n",
      "indiagm@lambdaschool.com\n",
      "RT @ZimVC: Does anyone in my network know a company hiring developers/eng. talent in Austin, TX?\n",
      "\n",
      "I have an incredible student in Austin th‚Ä¶\n",
      "Meet three more Lambda School students! \n",
      "\n",
      "Help any of them get hired and we'll pay you $1,000.\n",
      "\n",
      "Email the address for each and I'll connect you with them &amp; your career coach immediately.\n",
      "RT @paulg: Save this tweet in case you ever find yourself attacked by a mob of haters, and it makes you start to doubt yourself. Lambda doe‚Ä¶\n",
      "LAMBDA SCHOOL!!!\n",
      "Despite better judgment I'm at a conference. If you're at ASU/GSV say hello.\n",
      "Lambda School is building out an engineering team in our San Francisco office to help our efforts scale. \n",
      "\n",
      "Starting with a Director of Engineering.\n",
      "\n",
      "Director: https://t.co/htRVhrMM2l\n",
      "RT @calebhicks: Looking for someone who geeks out on AWS in all of it‚Äôs glory to help us equip every Lambda School student with modern clou‚Ä¶\n",
      "Few people realize this, but a *whole lot* of the university educational experience is already being outsourced https://t.co/zM2Wr2YuTW\n",
      "2U to acquire Trilogy Education for $750m https://t.co/6cVIpwuYOr.\n",
      "\n",
      "First real exit in the space.\n",
      "Stumbled into Communist twitter debating the merits of Lambda School.\n",
      "\n",
      "Have a hunch we‚Äôre not gonna see eye to eye.\n",
      "A VC picks up a $100 bill from off the ground.\n",
      "\n",
      "Twenty other VCs start crawling around looking for the other $50 bills that must certainly be nearby. https://t.co/oM6R2EFey3\n",
      "If we can fix the misallocation of human capital, what impact would that have on economic productivity? On GDP?\n",
      "\n",
      "We have the biggest, most unoptimized asset class ever right in front of us, one that directly impacts everyone, and very few directly doing anything about it.\n",
      "Lambda team: don‚Äôt take this for granted, even if folks outside assume it‚Äôs true. We‚Äôre nowhere close to having won yet. https://t.co/LtsEQOFeRB\n",
      "Apparently my daughter figured out how to tweet pictures, which my wife saw and deleted, but I like this one so I‚Äôm tweeting it again https://t.co/h5Tn5oMZe9\n",
      "RT @business: A new school in California lets you pay your tuition by essentially selling shares in your future self. It's an economist's d‚Ä¶\n",
      "You would think given the character limit people would be super generous on Twitter in giving the benefit of the doubt when interpreting what someone says.\n",
      "\n",
      "Somehow it‚Äôs the complete opposite. The most nitpicky platform ever.\n",
      "ATTENTION INDIA\n",
      "\n",
      "If you‚Äôre a company in India and would like to hire Lambda School graduates soon\n",
      "\n",
      "Email india@lambdaschool.com with:\n",
      "\n",
      "* Name of company\n",
      "* City/location\n",
      "* Number of hires/year (approximate)\n",
      "* Role(s)\n",
      "* Salary (in lakhs)\n",
      "\n",
      "Let‚Äôs just say your wish just may come true\n",
      "RT @jasonlmodisett: Y‚Äôall I just got home from a 2 day trip to LA where I had an interview with a great tech company. And no matter the out‚Ä¶\n",
      "RT @mcmonaghan: Just interviewed our first two candidates for @beartooth from @Austen's @LambdaSchool  Smoking!\n",
      "I have a problem https://t.co/4a8HxtonZa\n",
      "It‚Äôs Lambda School meetup day!\n",
      "\n",
      "Just a sampler:\n",
      "\n",
      "Miami\n",
      "Boston\n",
      "Arkansas\n",
      "Oklahoma https://t.co/F9op3FdY2e\n",
      "The past 4 days at Lambda School:\n",
      "\n",
      "19 students with job offers\n",
      "\n",
      "13 hired at companies that have hired multiple students\n",
      "Geez, they keep rolling in.\n",
      "\n",
      "10 Lambda School students with job offers today alone ü§Ø\n",
      "Edit: 13 of the 17 offers received by Lambda School students in the past 4 days are at companies that have hired more than one student.\n",
      "\n",
      "It's happening. https://t.co/j6LWqajyuO\n",
      "Technically equity is an uncapped unsecured loan with variable payback based on performance and no covenants and a forgiveness clause, sure.\n",
      "\n",
      "Technically a bus is just a car with a lot of people that makes planned stops.\n",
      "\n",
      "There are reasons we create new words for things. https://t.co/hivIdbl4RD\n",
      "RT @calebhicks: Not a student but want to get involved in your local Lambda community? Check out our Mentor Program, we‚Äôd love to have you.‚Ä¶\n",
      "Of the 14 job offers Lambda School students have received in the past 4 days, 10 are at companies that have hired more than one student üßê\n",
      "RT @juliejonak: @LambdaSchool First Friday meetup.... in THAILAND! üî• Paul is actually in my same cohort! We shared amazing food, conversati‚Ä¶\n",
      "Students pay for this tech school with a share of their earnings. Could it be the future of college finance?\n",
      "\n",
      "Today in the LA Times via @tylercowen \n",
      "\n",
      "https://t.co/2cJLT613mT\n",
      "Amazing https://t.co/sfamA85taH\n",
      "San Francisco is such a wild place.\n",
      "\n",
      "‚ÄúSure nobody can afford to live here, but we painstakingly built that parking lot. \n",
      "\n",
      "That laundromat was built in the 70s and now has historical significance. Plus the new building would cast a shadow, so...‚Äù\n",
      "It‚Äôs a parking lot. This tweet is literally describing a parking lot. https://t.co/gZ2VOAF6AG\n",
      "RT @abarrallen: ‚ÄúPush a button, get a job!‚Äù Before Uber and Lambda School, this model didn‚Äôt exist. You needed to submit a resume, intervie‚Ä¶\n",
      "There are few experiences anywhere as frustrating as trying to buy clothes on Amazon\n",
      "Just FYI:\n",
      "\n",
      "Interest for the Summer Hackers Program has been so extreme we‚Äôll only be able to accept a tiny percentage of applicants (&lt;5%) so please don‚Äôt take a denial as... much of anything, really.\n",
      "Sometimes I go to inforwars dot com just to look at the ads https://t.co/Pk5I2rcgoq\n",
      "Incentives\n",
      "RT @tylercowen: Is income-sharing finally ready to work?: https://t.co/nwgttDQ2rg\n",
      "To be clear (some people don't understand this):\n",
      "\n",
      "Lambda School doesn't charge anything to companies to hire from our student base. We provide these services free (for now):\n",
      "\n",
      "https://t.co/F1hq9B7PPb\n",
      "RT @business: If you could sell shares in your future earnings, would you? @tylercowen on the Lambda School's innovative new model for educ‚Ä¶\n",
      "Meet three Lambda School students today: help any of them get hired and I‚Äôll send you $1,000 (or you can donate it to a charity of your choice).\n",
      "\n",
      "(1/4)\n",
      "There‚Äôs nothing quite like that first time you realize just how broken the American healthcare system is https://t.co/JY1PBarFOd\n",
      "Tomorrow I‚Äôm going to start highlighting a few students per day. I‚Äôll only highlight students who our team have signed off on and are hire-ready.\n",
      "\n",
      "If you help them get hired I‚Äôll pay you $1,000. Per student. Open bounty.\n",
      "\n",
      "Watch this space at 9 AM Pacific.\n",
      "RT @Austen: Let's try something wild.\n",
      "\n",
      "Email me where you're at hey@lambdaschool.com, and I'll email you a Lambda School student profile wh‚Ä¶\n",
      "This tweet goes out to the one person in every office who reads Hacker News and posts all of the interesting links in Slack\n",
      "I‚Äôm not a PR expert, but I‚Äôve got to think, ‚Äúlet‚Äôs organize to make people miss their flights‚Äù is not a winning strategy https://t.co/2nWNSp7V6z\n",
      "Based on what I know about invention the key is accidentally dropping things on hot stoves https://t.co/oB8Hl1Axah\n",
      "I don‚Äôt even hear about people hired making 3-4x what they used to until I check our stats.\n",
      "\n",
      "That‚Äôs always a fantastic surprise. https://t.co/z4EYi0vYOF\n",
      "Can‚Äôt imagine how scary it must have been to make that jump.\n",
      "\n",
      "From high school orchestra teacher (for ten years) to software engineer, hired before graduation.\n",
      "\n",
      "Congratulations Matt! https://t.co/lhm6z02cgU\n",
      "I love that Rippling used a memo instead of a deck to raise, but you have to admit the steps to raising for them really were:\n",
      "\n",
      "1. Be Parker Conrad\n",
      "2. Have a revenue *growth* graph that is up and to the right while building on double digit million ARR (ü§Ø) https://t.co/MBXWpgoKrU\n"
     ]
    }
   ],
   "source": [
    "from mytwit.__init__ import *\n",
    "from mytwit.twitter import *\n",
    "\n",
    "with APP.app_context():\n",
    "    name = 'Austen'\n",
    "    tweets = User.query.filter(User.name == name).one().tweets\n",
    "    for tweet in tweets:\n",
    "        print(tweet.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`with APP.app_context` was needed above, because we're running from a notebook instead of inside `flask run` or `flask shell`. For more information, see:\n",
    "\n",
    "- http://flask-sqlalchemy.pocoo.org/2.3/contexts/\n",
    "- http://flask.pocoo.org/docs/1.0/appcontext/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Route in `TwitOff/twitoff/app.py`\n",
    "\n",
    "Within the `create_app` factory function\n",
    "\n",
    "```\n",
    "    @app.route('/user/<name>')\n",
    "    def user(name):\n",
    "        tweets = User.query.filter(User.name == name).one().tweets\n",
    "        return render_template('user.html', title=name, tweets=tweets)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Template at `TwitOff/twitoff/templates/user.html`\n",
    "\n",
    "`user.html` is like `base.html` except with a for loop iterating over tweets instead of users:\n",
    "\n",
    "```\n",
    "        {% for tweet in tweets %}\n",
    "        <span class=\"stack\">{{ tweet.text }}</span>\n",
    "        {% endfor %}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Add new user \n",
    "\n",
    "### From notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With [tqdm](https://github.com/tqdm/tqdm) for progress bars!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mytwit.__init__ import *\n",
    "from mytwit.twitter import *\n",
    "\n",
    "def add_user(username):\n",
    "    \"\"\"Add a user and their Tweets\"\"\"\n",
    "    twitter_user = TWITTER.get_user(username)\n",
    "    db_user = User(id=twitter_user.id, name=username)\n",
    "    DB.session.add(db_user)\n",
    "    \n",
    "    # We want as many recent non-retweet/reply statuses as we can get\n",
    "    # 200 is a Twitter API limit, we'll usually see less due to exclusions\n",
    "    tweets = twitter_user.timeline(\n",
    "        count=200, exclude_replies=True, include_rts=False,\n",
    "        tweet_mode='extended')\n",
    "    db_user.newest_tweet_id = tweets[0].id\n",
    "    \n",
    "    # tqdm adds progress bar\n",
    "    for tweet in tqdm(tweets): \n",
    "        # Calculate embedding on the full tweet, but truncate for storing\n",
    "        embedding = BASILICA.embed_sentence(tweet.full_text,\n",
    "                                            model='twitter')\n",
    "        db_tweet = Tweet(id=tweet.id, text=tweet.full_text[:300],\n",
    "                         embedding=embedding)\n",
    "        db_user.tweets.append(db_tweet)\n",
    "        DB.session.add(db_tweet)\n",
    "\n",
    "    DB.session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flask.app.Flask"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(APP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0e6939bf1d847d8a4f9903f68e24e26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=91), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with APP.app_context():\n",
    "    add_user('KenJennings')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make it fault-tolerant: add _or update_ user\n",
    "\n",
    "What if you try to add a user that's already been added? You get a database error:\n",
    "\n",
    "> IntegrityError: UNIQUE constraint failed: user.id\n",
    "\n",
    "So, we'll make our function fault-tolerant and \"idempotent\"!\n",
    "\n",
    "#### [Idempotent REST APIs](https://restfulapi.net/idempotent-rest-apis/)\n",
    "\n",
    "> When making multiple identical requests has the same effect as making a single request ‚Äì then that REST API is called idempotent.\n",
    "\n",
    ">When you design REST APIs, you must realize that API consumers can make mistakes. They can write client code in such a way that there can be duplicate requests as well. These duplicate requests may be unintentional as well as intentional some time (e.g. due to timeout or network issues). You have to design fault-tolerant APIs in such a way that duplicate requests do not leave the system unstable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, instead of assigning `db_user` to a new `User` ...\n",
    "\n",
    "```\n",
    "db_user = User(...)\n",
    "```\n",
    "\n",
    "We can assign `db_user` to an existing `User` **or** a new `User`:\n",
    "\n",
    "```\n",
    "    db_user = (User.query.get(twitter_user.id) or\n",
    "               User(id=twitter_user.id, name=username))\n",
    "```\n",
    "\n",
    "This is a common pattern in web applications. If `User.query.get(twitter_user.id)` returns `None`, that is `False`-y, so then `db_user` is assigned to the new `User(id=twitter_user.id, name=username))` instead.\n",
    "\n",
    "Here's a simpler demo of how **`or`** works in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 or 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "None or 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now here's our `add_or_update_user` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_or_update_user(username):\n",
    "    \"\"\"Add or update a user and their Tweets\"\"\"\n",
    "    twitter_user = TWITTER.get_user(username)\n",
    "    db_user = (User.query.get(twitter_user.id) or\n",
    "               User(id=twitter_user.id, name=username))\n",
    "    DB.session.add(db_user)\n",
    "    \n",
    "    # We want as many recent non-retweet/reply statuses as we can get\n",
    "    # 200 is a Twitter API limit, we'll usually see less due to exclusions\n",
    "    tweets = twitter_user.timeline(\n",
    "        count=200, exclude_replies=True, include_rts=False,\n",
    "        tweet_mode='extended', since_id=db_user.newest_tweet_id)\n",
    "    if tweets:\n",
    "        db_user.newest_tweet_id = tweets[0].id\n",
    "        \n",
    "    # tqdm adds progress bar    \n",
    "    for tweet in tqdm(tweets):\n",
    "        # Calculate embedding on the full tweet, but truncate for storing\n",
    "        embedding = BASILICA.embed_sentence(tweet.full_text,\n",
    "                                            model='twitter')\n",
    "        db_tweet = Tweet(id=tweet.id, text=tweet.full_text[:300],\n",
    "                         embedding=embedding)\n",
    "        db_user.tweets.append(db_tweet)\n",
    "        DB.session.add(db_tweet)\n",
    "        \n",
    "    DB.session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two more changes were made in the function above. \n",
    "\n",
    "[Tweepy has a `since_id` parameter:](http://docs.tweepy.org/en/3.7.0/api.html?highlight=since_id)\n",
    "\n",
    "> `since_id` ‚Äì Returns only statuses with an ID greater than (that is, more recent than) the specified ID.\n",
    "\n",
    "We use this parameter so we don't re-retrieve and re-embed tweets we already have in the database. (If `db_user.newest_tweet_id` is `None` then Tweepy gets all the tweets.)\n",
    "\n",
    "Also, we check whether a user has any tweets before trying to access the id of their 0th tweet. (This will prevent an error if a user doesn't have any tweets.)\n",
    "\n",
    "```\n",
    "    if tweets:\n",
    "        db_user.newest_tweet_id = tweets[0].id\n",
    "```\n",
    "\n",
    "Now the function is \"idempotent\"!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdfcf5a47d964c3997265ef0a49a8b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with APP.app_context():\n",
    "    add_or_update_user('KenJennings')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can add more fault-tolerance, with try / except / else blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_or_update_user(username):\n",
    "    \"\"\"Add or update a user and their Tweets, error if not a Twitter user.\"\"\"\n",
    "    try:\n",
    "        twitter_user = TWITTER.get_user(username)\n",
    "        db_user = (User.query.get(twitter_user.id) or\n",
    "                   User(id=twitter_user.id, name=username))\n",
    "        DB.session.add(db_user)\n",
    "        # We want as many recent non-retweet/reply statuses as we can get\n",
    "        # 200 is a Twitter API limit, we'll usually see less due to exclusions\n",
    "        tweets = twitter_user.timeline(\n",
    "            count=200, exclude_replies=True, include_rts=False,\n",
    "            tweet_mode='extended', since_id=db_user.newest_tweet_id)\n",
    "        if tweets:\n",
    "            db_user.newest_tweet_id = tweets[0].id         \n",
    "        # tqdm adds progress bar\n",
    "        for tweet in tqdm(tweets):\n",
    "            # Calculate embedding on the full tweet, but truncate for storing\n",
    "            embedding = BASILICA.embed_sentence(tweet.full_text,\n",
    "                                                model='twitter')\n",
    "            db_tweet = Tweet(id=tweet.id, text=tweet.full_text[:300],\n",
    "                             embedding=embedding)\n",
    "            db_user.tweets.append(db_tweet)\n",
    "            DB.session.add(db_tweet)\n",
    "    except Exception as e:\n",
    "        print('Error processing {}: {}'.format(username, e))\n",
    "        raise e\n",
    "    else:\n",
    "        DB.session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Add multiple users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_users(users):\n",
    "    \"\"\"\n",
    "    Add/update a list of users (strings of user names).\n",
    "    May take awhile, so run \"offline\" (interactive shell).\n",
    "    \"\"\"\n",
    "    # tqdm adds progress bar\n",
    "    for user in tqdm(users):\n",
    "        add_or_update_user(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "555c623d50d5444cbaa77adea67ab9db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2535be12bf574238a9dd9bcdfc17d785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55eb9f56135b40e8897f9c9cf3516d64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4476a70baa3e48eab80eaa923c6a1323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "users = ['calebhicks', 'SteveMartinToGo', 'sadserver']\n",
    "\n",
    "with APP.app_context():\n",
    "    add_users(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Update all users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_all_users():\n",
    "    \"\"\"Update all Tweets for all Users in the User table.\"\"\"\n",
    "    # tqdm adds progress bar\n",
    "    for user in tqdm(User.query.all()):\n",
    "        add_or_update_user(user.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaa192b948a4416593fb65f646ad18eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=13), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac66fb8cbd049fb9f9287a831a8c751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fe83ae691cd4a769c4902f52245bc9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "409eb2b85ae84edd8d3249e71f6ed58f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3c94877cb7b466f9df71987c49d7321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "514fc69ab4e949b49fed511985cd7a92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22ead00476ca4cbabf7114fbd9460015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51c12777e29f463296e10e63910fd9a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04d80f34c3fc4a8faebb2168b4c3d701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d076bf0df6334624be7aea3313b64b2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "068eaf9772cf4cb58d40f1f6325a1de4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "693747c4d03d4a3eb17ec4099b408e03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01651718cc0d4a868baad8e9f51b69b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baba1c62935b45f794fc935a53a9d13e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with APP.app_context():\n",
    "    update_all_users()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASSIGNMENT\n",
    "\n",
    "#### Add these functions to your Flask app\n",
    "- Put `add_or_update_user`, `add_users`, and `update_all_users` in `twitter.py`\n",
    "- Remove the `tqdm` progress bars from the for loops\n",
    "- Import the functions in `app.py`\n",
    "\n",
    "#### Replace your `/user/<name>` route with these routes\n",
    "\n",
    "```\n",
    "    @app.route('/user', methods=['POST'])\n",
    "    @app.route('/user/<name>', methods=['GET'])\n",
    "    def user(name=None, message=''):\n",
    "        name = name or request.values['user_name']\n",
    "        try:\n",
    "            if request.method == 'POST':\n",
    "                add_or_update_user(name)\n",
    "                message = \"User {} successfully added!\".format(name)\n",
    "            tweets = User.query.filter(User.name == name).one().tweets\n",
    "        except Exception as e:\n",
    "            message = \"Error adding {}: {}\".format(name, e)\n",
    "            tweets = []\n",
    "        return render_template('user.html', title=name, tweets=tweets,\n",
    "                               message=message)\n",
    "```\n",
    "\n",
    "***You will also need to add this import to the top of the file:*** `from flask import request`\n",
    "\n",
    "#### Add an `/update` route\n",
    "\n",
    "It should be like the Root route. But first, it should call your function to update all users. And it can display an appropriate title on the page, such as \"All tweets updated!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Predict!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user1_name = 'Austen'\n",
    "user2_name = 'elonmusk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with APP.app_context():\n",
    "    user1 = User.query.filter(User.name == user1_name).one()\n",
    "    user2 = User.query.filter(User.name == user2_name).one()\n",
    "    user1_embeddings = np.array([tweet.embedding for tweet in user1.tweets])\n",
    "    user2_embeddings = np.array([tweet.embedding for tweet in user2.tweets])\n",
    "    user1_labels = np.ones(len(user1.tweets))\n",
    "    user2_labels = np.zeros(len(user2.tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((61, 768), (52, 768), (61,), (52,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user1_embeddings.shape, user2_embeddings.shape, user1_labels.shape, user2_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.260309  , -0.2633    ,  0.569704  , ...,  0.230238  ,\n",
       "         0.0434244 ,  0.230399  ],\n",
       "       [-0.367562  ,  0.319384  ,  0.389726  , ...,  0.526667  ,\n",
       "        -0.00434549, -0.107877  ],\n",
       "       [ 0.32024   , -0.0549341 ,  0.187368  , ...,  0.625672  ,\n",
       "        -0.437755  , -0.0250464 ],\n",
       "       ...,\n",
       "       [-0.64133   , -0.0183684 ,  0.403406  , ...,  0.738118  ,\n",
       "         0.142393  ,  0.312049  ],\n",
       "       [-0.0619171 , -0.219514  ,  0.891416  , ...,  0.661542  ,\n",
       "         0.500294  ,  0.0749681 ],\n",
       "       [ 0.065296  , -0.142881  ,  1.01534   , ...,  0.740994  ,\n",
       "         0.244514  , -0.101911  ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user1_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user1_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.623786 , -0.36228  ,  0.481585 , ...,  0.737665 ,  0.592326 ,\n",
       "         0.456442 ],\n",
       "       [-0.544913 , -0.302794 ,  0.668437 , ...,  0.22628  ,  0.291232 ,\n",
       "         0.234701 ],\n",
       "       [-0.812237 , -0.223204 ,  0.737502 , ...,  1.15634  ,  0.267936 ,\n",
       "         0.129276 ],\n",
       "       ...,\n",
       "       [-0.233671 , -0.421423 ,  1.15558  , ...,  0.590557 ,  0.704866 ,\n",
       "        -0.102063 ],\n",
       "       [-0.280309 , -0.626599 ,  1.00127  , ...,  0.905657 ,  0.838759 ,\n",
       "        -0.158449 ],\n",
       "       [-0.0939891, -0.0589629,  0.661137 , ...,  0.867942 ,  0.442749 ,\n",
       "        -0.166158 ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user2_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user2_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((113, 768), (113,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = np.vstack([user1_embeddings, user2_embeddings])\n",
    "labels = np.concatenate([user1_labels, user2_labels])\n",
    "\n",
    "embeddings.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=1000, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "log_reg.fit(embeddings, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.score(embeddings, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94871795, 0.78378378, 0.83783784])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(log_reg, embeddings, labels, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_text = 'Income Share Agreements align incentives. Welcome to the future of education.'\n",
    "tweet_embedding = BASILICA.embed_sentence(tweet_text, model='twitter')\n",
    "i = int(log_reg.predict(np.array(tweet_embedding).reshape(1, -1))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ^^^^^^ Austen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<basilica.Connection at 0x11a2b7c18>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASILICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(log_reg.predict_proba(np.array(tweet_embedding).reshape(1, -1))[0][i] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_text = 'SpaceX will launch another Tesla into orbit'\n",
    "tweet_embedding = BASILICA.embed_sentence(tweet_text, model='twitter')\n",
    "i = int(log_reg.predict(np.array(tweet_embedding).reshape(1, -1))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ^^^^^^ Musk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(log_reg.predict_proba(np.array(tweet_embedding).reshape(1, -1))[0][i] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11334337, 0.88665663]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_text = 'Today we launch a new initiative'\n",
    "tweet_embedding = BASILICA.embed_sentence(tweet_text, model='twitter')\n",
    "log_reg.predict_proba(np.array(tweet_embedding).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(tweet_embedding).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([tweet_embedding]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# from mytwit.__init__ import *\n",
    "from mytwit.twitter import *\n",
    "from mytwit.models import DB, Tweet, User\n",
    "\n",
    "def predict_user(user1_name, user2_name, tweet_text):\n",
    "    user1 = User.query.filter(User.name == user1_name).one()\n",
    "    user2 = User.query.filter(User.name == user2_name).one()\n",
    "    user1_embeddings = np.array([tweet.embedding for tweet in user1.tweets])\n",
    "    user2_embeddings = np.array([tweet.embedding for tweet in user2.tweets])\n",
    "    user1_labels = np.ones(len(user1.tweets))\n",
    "    user2_labels = np.zeros(len(user2.tweets))\n",
    "    \n",
    "    embeddings = np.vstack([user1_embeddings, user2_embeddings])\n",
    "    labels = np.concatenate([user1_labels, user2_labels])\n",
    "\n",
    "    log_reg = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "    log_reg.fit(embeddings, labels)\n",
    "    \n",
    "    tweet_embedding = BASILICA.embed_sentence(tweet_text, model='twitter')\n",
    "    return log_reg.predict(np.array(tweet_embedding).reshape(1, -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_text = 'SpaceX will launch another Tesla into orbit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "user1 = 'Austen'\n",
    "user2 = 'elonmusk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction = predict_user(user1, user2, tweet_text)\n",
    "prediction = (0, 99)\n",
    "\n",
    "message = '\"{}\" is more likely to be said by {} than {}'.format(\n",
    "                tweet_text, user1 if prediction[0] else user2,\n",
    "                user2 if prediction[0] else user1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "message += ', with ' + str(prediction[1]) + ' percent confidence'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"SpaceX will launch another Tesla into orbit\" is more likely to be said by elonmusk than Austen, with 99 percent confidence'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASSIGNMENT\n",
    "\n",
    "### Create `TwitOff/twitoff/predict.py`\n",
    "\n",
    "Refactor the notebook code into a function, named `predict_user`.\n",
    "\n",
    "The code you need is already here. You just need to put it in a function in a `.py` file.\n",
    "\n",
    "The function should take three strings as parameters:\n",
    "- User 1 name\n",
    "- User 2 name\n",
    "- Tweet text\n",
    "\n",
    "The function should determine and return which user is more likely to say a given tweet. (`return log_reg.predict(...)`)\n",
    "\n",
    "Import what you need from `numpy`, `sklearn`, and your `.models` and `.twitter` modules.\n",
    "\n",
    "### Add this `/compare` route\n",
    "\n",
    "```\n",
    "    @app.route('/compare', methods=['POST'])\n",
    "    def compare(message=''):\n",
    "        user1, user2 = sorted([request.values['user1'],\n",
    "                               request.values['user2']])\n",
    "        if user1 == user2:\n",
    "            message = 'Cannot compare a user to themselves!'\n",
    "        else:\n",
    "            prediction = predict_user(user1, user2, request.values['tweet_text'])\n",
    "            message = '\"{}\" is more likely to be said by {} than {}'.format(\n",
    "                request.values['tweet_text'], user1 if prediction else user2,\n",
    "                user2 if prediction else user1)\n",
    "        return render_template('prediction.html', title='Prediction', message=message)\n",
    "```\n",
    "\n",
    "***You will also need to add this import to the top of the file:*** `from .predict import predict_user`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
